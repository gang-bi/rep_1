{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gang-bi/rep_1/blob/main/chapter02_mathematical_building_blocks_i%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qAQEq5v-8PH"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0L0Mks_-8PM"
      },
      "source": [
        "# The mathematical building blocks of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhJULUKW-8PN"
      },
      "source": [
        "## A first look at a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buw6ltYo-8PO"
      },
      "source": [
        "**Loading the MNIST dataset in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QO8p8LE_-8PO",
        "outputId": "927333d8-1e20-43fc-9021-95dccdee1d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# mnist에 데이터 업로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bbb6I-07-8PQ",
        "outputId": "3bd4e158-817e-4fd7-f1ec-0d8fe90aae86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_images.shape\n",
        "# 학습 이미지 데이터셋(train_image)의 차원: (60000, 28, 28) = 이미지 60000개, 28x28 픽셀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MpozCTLj-8PR",
        "outputId": "9ff4727c-4097-4aac-b6b5-c64af2af9f15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(train_labels)\n",
        "# 학습 이미지 데이터셋에 포함된 데이터의 총 개수: 60000"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AvuEBY8qCH5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_PMr2lfx-8PR",
        "outputId": "881cbd5b-e6f9-4965-dc5f-443660f55c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_labels\n",
        "# 학습 데이터셋의 레이블 배열을 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2BdO3AC_-8PS",
        "outputId": "ffb719b5-b202-4ca0-9fe3-43b97e23a7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "test_images.shape\n",
        "# 테스트 이미지 데이터셋(test_images)의 차원: (10000, 28, 28) = 이미지 10000개, 28x28 픽셀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TyaGvR1X-8PS",
        "outputId": "927fa6e7-a324-4d55-ea8e-11a8f9190ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(test_labels)\n",
        "# 테스트 이미지 데이터셋에 포함된 데이터의 총 개수: 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "i5nBIfOk-8PT",
        "outputId": "47d97f5a-18ae-4abb-f524-214ddbcbd821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "test_labels\n",
        "# 테스트 데이터셋의 레이블 배열을 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my81FL4Y-8PT"
      },
      "source": [
        "**The network architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B0FABjTU-8PT"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wAjunMAeGMn2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBJHaHr1-8PU"
      },
      "source": [
        "**The compilation step: 모델 구축 단계**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8TO1eMUj-8PU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtE_iEQ_-8PV"
      },
      "source": [
        "**Preparing the image data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8ZN0Wquw-8PV"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "# 차원 변경: 2차원(28x28) -> 1차원(28*28=784)\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "# 데이터 타입을 \"foat32\"로 변경\n",
        "# 모든 픽셀 값이 0~1이 되도록 정규화: 원본 MNIST 데이터셋의 픽셀 값은 0부터 255까지의 정수값을 가지기 때문에 225로 나눠 0~1 사이의 값을 갖도록 함.\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "# 차원 변경: 2차원(28x28) -> 1차원(28*28=784)\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "# 데이터 타입을 \"foat32\"로 변경\n",
        "# 모든 픽셀 값이 0~1이 되도록 정규화: 원본 MNIST 데이터셋의 픽셀 값은 0부터 255까지의 정수값을 가지기 때문에 225로 나눠 0~1 사이의 값을 갖도록 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-7SYjbM-8PW"
      },
      "source": [
        "**\"Fitting\" the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "goAAtzyn-8PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9adf96e-b1d2-4a05-f6bc-0db42a3ca135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 6s 10ms/step - loss: 0.2613 - accuracy: 0.9251\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.1057 - accuracy: 0.9689\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0699 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0506 - accuracy: 0.9852\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0376 - accuracy: 0.9888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e1d98587fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "# epoch=5: 전체 학습 과정은 5회 반복\n",
        "# batch_size=128: 한 번에 네트워크에 전달되는 데이터의 사이즈가 128\n",
        "# model.fit: 모델의 학습 과정을 실행시키며, 설정된 epoch 수와 배치 사이즈에 따라 최적화된 모델의 가중치를 업데이트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL0-6i-f-8PW"
      },
      "source": [
        "**Using the model to make predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YYG7noXi-8PW",
        "outputId": "b52dca77-b199-4c43-d27e-4c5a54a65da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.4573593e-08, 4.5657216e-09, 6.6513685e-06, 1.8375907e-04,\n",
              "       4.9889492e-11, 2.7879913e-08, 2.3684098e-11, 9.9980330e-01,\n",
              "       5.5638534e-08, 6.0346183e-06], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "test_digits = test_images[0:10]\n",
        "# 배열에서 처음 10개의 이미지를 선택하여 test_digits 변수에 저장\n",
        "predictions = model.predict(test_digits)\n",
        "# model.predict 메서드를 사용하여 test_digits에 대한 예측을 수행 후 각 클래스에 대한 예측 확률을 배열로 반환\n",
        "# 즉, 0부터 10까지의 각 이미지가 어떤 숫자와 가장 가까운지를 반영한 확률을 계산하고, 이를 배열로 반환하여 저장.\n",
        "predictions[0]\n",
        "# 0~10번째 이미지들 중 0번째 이미지에 대한 예측 결과를 담은 배열로, 10개 클래스 각각에 속할 확률을 나타냄."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oZKniEqP-8PW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9102ec-de48-48b8-efbe-1d75747ecd6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "predictions[0].argmax()\n",
        "# 0번째 이미지들 중 가장 높은 예측 확률을 가지는 값을 반환: 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2qpXjS4J-8PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f977c33f-06c1-4b35-d6a4-e8249576b211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9998033"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "predictions[0][7]\n",
        "# 0번째 이미지의 7번째 배열을 조회: 0번째 이미지가 숫자'7'일 확률을 알 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9BaSqvM4-8PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1881b2-fdc1-4109-a21a-7272c4287d18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_labels[0]\n",
        "# 0번째 이미지의 예측에 대한 정답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ee4XmHs-8PX"
      },
      "source": [
        "**Evaluating the model on new data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z6c8Mkor-8PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0091c640-ce64-4a64-efe5-9cd4a30ae2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9807\n",
            "test_acc: 0.9807000160217285\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "# 모델의 손실값, 모델의 정확도 = 모델 평가(테스트 데이터, 정답 데이터)\n",
        "print(f\"test_acc: {test_acc}\")\n",
        "# 파이썬의 f-string을 사용하여, test_acc 변수에 저장된 테스트 정확도를 문자열로 포맷하여 출력: accuracy: 0.98 -> 98%의 정확도로 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bec7iWrK-8PY"
      },
      "source": [
        "## Data representations for neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXohDJA3-8PY"
      },
      "source": [
        "### Scalars (rank-0 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IISq2kzg-8PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77292280-3a91-45a8-8a25-4c5067aa8343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(12)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import numpy as np\n",
        "x = np.array(12)\n",
        "# 12라는 스칼라 값을 갖는 NumPy 0차원 배열 생성\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "R7Ybo_qO-8PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a02fe8f-6a22-44d9-f100-e3714e16dc49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "x.ndim\n",
        "# x의 차원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zx1zyTX-8PY"
      },
      "source": [
        "### Vectors (rank-1 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ENj55OcX-8PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8a5b36-c6b1-4fc8-dfaa-c2f2da48e2e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12,  3,  6, 14,  7])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x = np.array([12, 3, 6, 14, 7])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x-om4z9z-8PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71aab8bc-1442-4555-94d8-6b1382e76ec0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x.ndim\n",
        "# 벡터가 1개 있으므로, 1차원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YgnfYig-8PZ"
      },
      "source": [
        "### Matrices (rank-2 tensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VEVOm1di-8PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c3d836-0898-49c4-f668-01db187e31bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "x = np.array([[5, 78, 2, 34, 0],\n",
        "              [6, 79, 3, 35, 1],\n",
        "              [7, 80, 4, 36, 2]])\n",
        "# 3행 5열의 데이터\n",
        "x.ndim\n",
        "# 따라서 2차원 데이터"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryJXe5tB-8Pa"
      },
      "source": [
        "### Rank-3 and higher-rank tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZcQk3Si-8Pa"
      },
      "outputs": [],
      "source": [
        "x = np.array([[[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]],\n",
        "              [[5, 78, 2, 34, 0],\n",
        "               [6, 79, 3, 35, 1],\n",
        "               [7, 80, 4, 36, 2]]])\n",
        "# 3행 5열의 데이터가 3개 있는 형태\n",
        "x.ndim\n",
        "# 따라서 3차원"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_syskv_k-8Pa"
      },
      "source": [
        "### Key attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "B8M_T6_g-8Pa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Gdftt1Dm-8Pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fff33ed-c4a8-4165-f0e1-48a01d8e274f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train_images.ndim\n",
        "# (60000, 28, 28)이므로 3차원"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hznSD5_W-8Pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28b520c-ae36-41d1-de79-5e18fec70983"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NawlqfMT-8Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1027fd6c-153a-4996-e5a7-3d168fa81194"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "train_images.dtype\n",
        "# dtype('unit8'): 8바이트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N67B9pr4-8Pk"
      },
      "source": [
        "**Displaying the fourth digit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "n7woLEL4-8Pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "0fd82522-4026-41ba-e344-7b95b6342107"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "digit = train_images[4]\n",
        "# train_images 배열에서 5번째 이미지(인덱스 4)를 선택하여 digit 변수에 저장\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "# plt.imshow: 함수는 이미지 데이터를 그래픽으로 표시, digit: 표시할 이미지 데이터, cmap=plt.cm.binary: color map을 이진으로 설정 -> 이미지가 흑백으로 표현\n",
        "plt.show()\n",
        "# plt.imshow 함수를 사용해 준비된 이미지를 화면에 표시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ly-37RUs-8Pk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d077ec67-a54d-4879-d9a0-7ad0bfa5d8ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "train_labels[4]\n",
        "# 5번째 이미지의 정답: 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRdHCGgn-8Pk"
      },
      "source": [
        "### Manipulating tensors in NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "OwT-UZhl-8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ba6114-4edb-4c1b-83a2-6013a0ec6390"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "my_slice = train_images[10:100]\n",
        "# train_image에 있는 이미지들 중 11~100번째 이미지를 선택하여 my_slice에 저장\n",
        "my_slice.shape\n",
        "# (90, 28, 28) = (개수, 픽셀 축, 픽셀 축)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LjxQVBPg-8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15285a67-5a96-46ac-d055-ae935d773e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "my_slice = train_images[10:100, :, :]\n",
        "# train_image에 있는 이미지들 중 11~100번째 이미지를 선택하되, 선택된 각 이미지의 모든 행(:)과 열(:)을 포함함.\n",
        "# *위 코드와 결과는 같지만 조금 더 명시적인 코드임*\n",
        "my_slice.shape\n",
        "# (90, 28, 28) = (개수, 픽셀 축, 픽셀 축)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "SMdStu-8-8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417b43a4-3d1c-4144-c180-bdfd95edc569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "my_slice = train_images[10:100, 0:28, 0:28]\n",
        "# train_image에 있는 이미지들 중 11~100번째 이미지를 선택, 행과 열 모두 0~27번째 값을 포함\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rgnuPdwD-8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8825f8-e0f9-4539-d6c0-74f1a5eae0d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "my_slice = train_images[:, 14:, 14:]\n",
        "# train_image에 있는 모든 이미지들을 선택, 행과 열 모두 14~끝까지 있는 값을 포함\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CW2MEHH1-8Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b70a143-f9a5-4a45-b011-962797d46632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "my_slice = train_images[:, 7:-7, 7:-7]\n",
        "# train_image에 있는 모든 이미지들을 선택, 행과 열 모두 처음 7번째 값 ~ 끝에서 7번째 값(21번째 값)을 선택\n",
        "my_slice.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(my_slice[4], cmap=plt.cm.binary)\n",
        "# 14x14 이미지 출력\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "3hf8AKfPYENp",
        "outputId": "bcd01a48-54bf-4fb6-812c-ccc063c9c1d6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz8tu2Dd-8Pm"
      },
      "source": [
        "### The notion of data batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nGOIOoPh-8Pm"
      },
      "outputs": [],
      "source": [
        "batch = train_images[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ue8-I4u-8Pm"
      },
      "outputs": [],
      "source": [
        "batch = train_images[128:256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuHyTEie-8Pm"
      },
      "outputs": [],
      "source": [
        "n = 3\n",
        "batch = train_images[128 * n:128 * (n + 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT-Y0nCK-8Pn"
      },
      "source": [
        "### Real-world examples of data tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6YeDX11-8Pn"
      },
      "source": [
        "### Vector data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gjPOJ8m-8Pp"
      },
      "source": [
        "### Timeseries data or sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0jwKOpk-8Pp"
      },
      "source": [
        "### Image data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he0AVvwI-8Pp"
      },
      "source": [
        "### Video data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs2PZ59Y-8Pp"
      },
      "source": [
        "## The gears of neural networks: tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qym0CWhM-8Pp"
      },
      "source": [
        "### Element-wise operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DQ-jiIW-8Pq"
      },
      "outputs": [],
      "source": [
        "def naive_relu(x):\n",
        "    assert len(x.shape) == 2\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] = max(x[i, j], 0)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKTtZ_WF-8Pq"
      },
      "outputs": [],
      "source": [
        "def naive_add(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert x.shape == y.shape\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[i, j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVDRvv7o-8Pq"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = x + y\n",
        "    z = np.maximum(z, 0.)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9GN6ITp-8Pq"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "    z = naive_add(x, y)\n",
        "    z = naive_relu(z)\n",
        "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkqPVx5y-8Pr"
      },
      "source": [
        "### Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2CxAUYi-8Pr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.random.random((32, 10))\n",
        "y = np.random.random((10,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vhrAkUO-8Pr"
      },
      "outputs": [],
      "source": [
        "y = np.expand_dims(y, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laXzbKqR-8Pr"
      },
      "outputs": [],
      "source": [
        "Y = np.concatenate([y] * 32, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T464n_MA-8Pr"
      },
      "outputs": [],
      "source": [
        "def naive_add_matrix_and_vector(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    x = x.copy()\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            x[i, j] += y[j]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHSzEaCw-8Pr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7bvU4R0-8Ps"
      },
      "source": [
        "### Tensor product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_rI02_e-8Ps"
      },
      "outputs": [],
      "source": [
        "x = np.random.random((32,))\n",
        "y = np.random.random((32,))\n",
        "z = np.dot(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpOJeaW1-8Ps"
      },
      "outputs": [],
      "source": [
        "def naive_vector_dot(x, y):\n",
        "    assert len(x.shape) == 1\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    z = 0.\n",
        "    for i in range(x.shape[0]):\n",
        "        z += x[i] * y[i]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Di89dK1-8Ps"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 1\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(x.shape[1]):\n",
        "            z[i] += x[i, j] * y[j]\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9B7E7jc-8Pt"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_vector_dot(x, y):\n",
        "    z = np.zeros(x.shape[0])\n",
        "    for i in range(x.shape[0]):\n",
        "        z[i] = naive_vector_dot(x[i, :], y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4_uPnYX-8Pt"
      },
      "outputs": [],
      "source": [
        "def naive_matrix_dot(x, y):\n",
        "    assert len(x.shape) == 2\n",
        "    assert len(y.shape) == 2\n",
        "    assert x.shape[1] == y.shape[0]\n",
        "    z = np.zeros((x.shape[0], y.shape[1]))\n",
        "    for i in range(x.shape[0]):\n",
        "        for j in range(y.shape[1]):\n",
        "            row_x = x[i, :]\n",
        "            column_y = y[:, j]\n",
        "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9paUP2u-8Pt"
      },
      "source": [
        "### Tensor reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k4aBUSY-8Pt"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofoNvr-W-8Pt"
      },
      "outputs": [],
      "source": [
        "x = np.array([[0., 1.],\n",
        "             [2., 3.],\n",
        "             [4., 5.]])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ95oOni-8Pu"
      },
      "outputs": [],
      "source": [
        "x = x.reshape((6, 1))\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-kLb37E-8Pu"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((300, 20))\n",
        "x = np.transpose(x)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDg9aWA--8Pu"
      },
      "source": [
        "### Geometric interpretation of tensor operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VJ5YFjF-8Pu"
      },
      "source": [
        "### A geometric interpretation of deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi2KroAf-8Pu"
      },
      "source": [
        "## The engine of neural networks: gradient-based optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_AgYITr-8Pv"
      },
      "source": [
        "### What's a derivative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqgVu3Bw-8Pv"
      },
      "source": [
        "### Derivative of a tensor operation: the gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwciUvo1-8Pv"
      },
      "source": [
        "### Stochastic gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b51mrAHg-8Pv"
      },
      "source": [
        "### Chaining derivatives: The Backpropagation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1hrcEt1-8Pv"
      },
      "source": [
        "#### The chain rule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCvyHeEb-8Pv"
      },
      "source": [
        "#### Automatic differentiation with computation graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MkISN37-8Pv"
      },
      "source": [
        "#### The gradient tape in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72F8qJEI-8Pw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "x = tf.Variable(0.)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8cpsKVT-8Pw"
      },
      "outputs": [],
      "source": [
        "x = tf.Variable(tf.random.uniform((2, 2)))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UcVlzYO-8Pw"
      },
      "outputs": [],
      "source": [
        "W = tf.Variable(tf.random.uniform((2, 2)))\n",
        "b = tf.Variable(tf.zeros((2,)))\n",
        "x = tf.random.uniform((2, 2))\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.matmul(x, W) + b\n",
        "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4psW5dVv-8Px"
      },
      "source": [
        "## Looking back at our first example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkfB9_pN-8Px"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aHPCvqY-8Px"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyFEV23o-8Px"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEGYP-BB-8Py"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV9sEIjn-8Py"
      },
      "source": [
        "### Reimplementing our first example from scratch in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A5uormB-8Py"
      },
      "source": [
        "#### A simple Dense class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hrQStYD-8Pz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL3m7DE8-8Pz"
      },
      "source": [
        "#### A simple Sequential class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_ju5bjK-8Pz"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqeLGUsa-8P0"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9Y2X91I-8P0"
      },
      "source": [
        "#### A batch generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG5DrcP7-8P1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deTt6wnV-8P1"
      },
      "source": [
        "### Running one training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lqSk8zV-8P1"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images_batch)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2E3Ifivu-8P1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXeNnOgK-8P2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2NhwlxY-8P2"
      },
      "source": [
        "### The full training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUyX8ljA-8P2"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCw_A8w--8P2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1XPXuKv-8P3"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "617pqoWl-8P3"
      },
      "outputs": [],
      "source": [
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_onikgt-8P3"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}